{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de09faac-c911-45aa-8c3f-1b59c1b19fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/ubuntu/graphseq-inference/\")\n",
    "from graphseq_inference.data_utils import *\n",
    "from graphseq_inference.models import *\n",
    "from graphseq_inference.train_utils import *\n",
    "\n",
    "#!python /home/ubuntu/graphseq-inference/graphseq_inference/generate_alpha.py > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d33774b-ead1-45ed-8cc4-d752e6309d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mid_trees(ts):\n",
    "\n",
    "    for i, tree in enumerate(ts.trees()):\n",
    "        if tree.interval.left >= (ts.sequence_length/2):\n",
    "            break\n",
    "\n",
    "    first_tree = i-249\n",
    "    last_tree = i + 250\n",
    "    \n",
    "    trees = []\n",
    "    for j, tree in enumerate(ts.aslist()):\n",
    "        if j >= first_tree and j <= last_tree:\n",
    "            trees.append(tree)\n",
    "            \n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08476866-911f-4849-b552-a872b6ae3919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mkdir validation_classification_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b01db1b9-9981-428a-8e60-387e64161650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#ls validation_classification_dataset | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "679d0022-799c-437c-bd65-da5d2ccf8d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf validation_classification_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc6b75-5bb4-4265-b090-efa103a0108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sleep 7200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311366d3-8b23-48ec-a52c-ff0f567db6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf './validation_classification_dataset/.ipynb_checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ae0f10-9bef-4676-b12a-ece7095e6051",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf './classification_dataset/.ipynb_checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3532c8-5b61-4edb-a2fb-16579326a403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec57d5-6751-4b0a-93af-0b5ea24e0169",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./classification_dataset/\"\n",
    "\n",
    "files = os.listdir(directory)\n",
    "files = [directory +  file for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4379677-b19b-42fa-adfe-1342b919ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc37e8d-a9cb-4f90-a9a8-189e8bef91e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581c953-bf41-4931-a7f0-0370e0fcec72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "624225a9-d4ca-4e08-8896-e8a7e8bcf6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_lookup = {\n",
    "    \"kingman_selection_none\" : 0,\n",
    "    \"kingman_selection_weak\" : 1,\n",
    "    \"kingman_selection_medium\" : 2,\n",
    "    \"kingman_selection_strong\" : 3,\n",
    "    \n",
    "    \"beta_selection_a1.99-1.75\" : 4,\n",
    "    \"beta_selection_a1.75-1.50\" : 5,\n",
    "    \"beta_selection_a1.50-1.25\" : 6,\n",
    "    \"beta_selection_a1.25-1.01\" : 7,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c535ed-e1ae-42fa-b9f6-705cecd0e4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba2b77-0833-46ff-88e1-b73ea1e9e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preorder_dist(tree):\n",
    "    result = []\n",
    "    for root in tree.roots:\n",
    "        stack = [(root, (-1, root) , (tree.get_time(tree.root), 0))]\n",
    "        while len(stack) > 0:\n",
    "            u, pc, time = stack.pop()\n",
    "            result.append((u, pc, time))\n",
    "            for v in tree.children(u):\n",
    "                stack.append((v, (u,v) , (tree.get_time(u),tree.get_time(v))))\n",
    "    return result\n",
    "\n",
    "def restructure_result(result):\n",
    "\n",
    "\n",
    "    is_modified = True\n",
    "    while True:\n",
    "\n",
    "        if not is_modified: break\n",
    "        is_modified = False\n",
    "\n",
    "        for i, (idx_node, (parent, node), (time_parent, time_node)) in enumerate(result):\n",
    "            branch_length = time_parent - time_node\n",
    "            \n",
    "            \n",
    "            \n",
    "            #if branch_length < (time_parent*threshold) and branch_length != 0 and (parent != node):\n",
    "            \n",
    "\n",
    "            threshold = 20\n",
    "            \n",
    "            if time_parent < 200:\n",
    "                threshold = 20\n",
    "            \n",
    "            if time_parent < 20:\n",
    "                threshold = 2\n",
    "                \n",
    "            if time_parent < 10:\n",
    "                threshold = 1\n",
    "                \n",
    "            if time_parent < 5:\n",
    "                threshold = 0.5\n",
    "                \n",
    "            \n",
    "            if branch_length < threshold and branch_length != 0 and (parent != node):\n",
    "    \n",
    "                \n",
    "                new_time = (time_parent+time_node)/2\n",
    "                result[i] = (-1, (parent, parent), (time_parent, time_parent))\n",
    "                for j, (_, (p, n), (tp, tn)) in enumerate(result):\n",
    "                    if node == n:\n",
    "                        result[j] = (-1, (p, parent), (tp, time_parent))#\n",
    "                    if node == p:\n",
    "                        result[j] = (-1, (parent, n), (time_parent, tn))\n",
    "\n",
    "                is_modified = True\n",
    "                break\n",
    "\n",
    "    new_result = []\n",
    "    for a, (b,c), (d, e) in result:\n",
    "        if b != c:\n",
    "            new_result.append((a, (b,c), (d,e)))\n",
    "    return new_result\n",
    "\n",
    "def multiple_mergerized_to_data_object(result):\n",
    "\n",
    "    G = nx.Graph()\n",
    "    for _, edge, times in result[:-1]:\n",
    "        a, b = edge\n",
    "        ta, tb = times\n",
    "        branch = ta - tb\n",
    "        G.add_weighted_edges_from([(a, b, branch)])\n",
    "        \n",
    "    data = from_networkx(G)\n",
    "    rename_data_attribute(data, \"weight\", \"edge_weight\") \n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tree_to_data_objects(tree, num_embedding=60):\n",
    "    max_num_nodes = 2 * 10 - 1 \n",
    "\n",
    "    data = from_networkx(nx.Graph(tree.as_dict_of_dicts()))\n",
    "    rename_data_attribute(data, \"branch_length\", \"edge_weight\") \n",
    "    num_nodes = data.num_nodes\n",
    "    data.x = torch.eye(max_num_nodes,num_embedding)\n",
    "    data.x[num_nodes:] = torch.zeros(num_embedding)\n",
    "    data.num_nodes = max_num_nodes\n",
    "    return data\n",
    "\n",
    "\n",
    "def tree_to_restructured_data_objects(tree, num_embedding=60):\n",
    "    result = preorder_dist(tree)\n",
    "    result.reverse()\n",
    "    result = restructure_result(result)    \n",
    "    data = multiple_mergerized_to_data_object(result)\n",
    "    \n",
    "    max_num_nodes = 2 * 10 - 1 \n",
    "    num_nodes = data.num_nodes\n",
    "    data.x = torch.eye(max_num_nodes,num_embedding)\n",
    "    data.x[num_nodes:] = torch.zeros(num_embedding)\n",
    "    data.num_nodes = max_num_nodes\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157ebe1d-8beb-4ae0-b4cc-2f8526b6981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_y_label_from_y_dict(y_dict):\n",
    "    reproduction_model, parameter = y_dict[\"model\"]\n",
    "\n",
    "    if reproduction_model == \"beta\":\n",
    "        if parameter < 1.25:\n",
    "            return torch.Tensor([7]).long()\n",
    "        if parameter < 1.5:\n",
    "            return torch.Tensor([6]).long()\n",
    "        if parameter < 1.75:\n",
    "            return torch.Tensor([5]).long()\n",
    "        if parameter < 2:\n",
    "            return torch.Tensor([4]).long()\n",
    "\n",
    "    else:\n",
    "        label = y_dict[\"model\"][0] + \"_selection_\" + y_dict[\"selection_type\"]\n",
    "        y = torch.Tensor([label_lookup[label]]).long()\n",
    "        return y\n",
    "\n",
    "def convert_for_classification(file: tskit.trees.TreeSequence,\n",
    "                                num_embedding:int = 60, restructure=False,\n",
    "                           ):\n",
    "    \n",
    "    ts, y_dict = torch.load(file)\n",
    "    \n",
    "    y = get_y_label_from_y_dict(y_dict)\n",
    "    \n",
    "    #label = y_dict[\"model\"][0] + \"_selection_\" + y_dict[\"selection_type\"]\n",
    "    #y = torch.Tensor([label_lookup[label]]).long()\n",
    "    trees = get_mid_trees(ts)\n",
    "    \n",
    "        \n",
    "    if restructure:\n",
    "        data_objects = [tree_to_restructured_data_objects(tree) for tree in trees]\n",
    "    else:\n",
    "        data_objects = [tree_to_data_objects(tree) for tree in trees]\n",
    "        \n",
    "    \n",
    "    for data in data_objects:\n",
    "        data.y = y\n",
    "    \n",
    "    \n",
    "    #for i, tree in enumerate(trees):            \n",
    "    #    data = from_networkx(nx.Graph(tree.as_dict_of_dicts()))\n",
    "    #    rename_data_attribute(data, \"branch_length\", \"edge_weight\") \n",
    "    #    num_nodes = data.num_nodes\n",
    "    #    data.x = torch.eye(max_num_nodes,num_embedding)\n",
    "    #    data.x[num_nodes:] = torch.zeros(num_embedding)\n",
    "    #    data.y = y\n",
    "    #    data.num_nodes = max_num_nodes\n",
    "    #    data_objects.append(data)\n",
    "        \n",
    "    return data_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72c07c39-b3b6-4c6c-8cea-1fe3f4c0fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = files[0]\n",
    "ts, y_dict = torch.load(file)\n",
    "y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aea0947b-6329-4242-afb2-61339b02f46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ('beta', 1.37),\n",
       " 'sequence_length': 409600000,\n",
       " 'selection_coefficient': 0,\n",
       " 'selection_type': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = files[2]\n",
    "ts, y_dict = torch.load(file)\n",
    "y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "69076931-94cd-4209-be2a-ca8999113a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ('beta', 1.74), 'sequence_length': 25600000, 'selection_coefficient': 0, 'selection_type': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_y_label_from_y_dict(y_dict):\n",
    "    reproduction_model, parameter = y_dict[\"model\"]\n",
    "\n",
    "    if reproduction_model == \"beta\":\n",
    "        if parameter < 1.25:\n",
    "            return torch.Tensor([7]).long()\n",
    "        if parameter < 1.5:\n",
    "            return torch.Tensor([6]).long()\n",
    "        if parameter < 1.75:\n",
    "            return torch.Tensor([5]).long()\n",
    "        if parameter < 2:\n",
    "            return torch.Tensor([4]).long()\n",
    "\n",
    "    else:\n",
    "        label = y_dict[\"model\"][0] + \"_selection_\" + y_dict[\"selection_type\"]\n",
    "        y = torch.Tensor([label_lookup[label]]).long()\n",
    "        return y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa78576-6824-460f-8230-55d1d035688e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37827073-a3d4-4912-88f8-2556f46a5ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbc2e12-d47e-4549-b84e-0092f8478fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, DemographyNet, num_classes, time_window=60):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(time_window, time_window//2)\n",
    "        self.l2 = nn.Linear(time_window//2, num_classes)\n",
    "        self.DemographyNet = DemographyNet\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        x = self.DemographyNet(batch)\n",
    "        return self.l2(F.relu(self.l1(x)))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7368a3a-313b-4b9b-b684-04780b037ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "demography_net = DiffPoolNet(19, 60, 192, 60)\n",
    "model = ClassificationModel(demography_net, num_classes=8).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "initialize_weights(model)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7da97947-3bee-4dc1-8ffc-7c05165ebb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_objects = convert_for_classification(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9d1e2da2-82af-4ba4-94af-0dfa87255a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_objects[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb000c5e-916f-40d6-ab4e-29be86b159c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf classifcation_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e4318-61d9-4061-9e55-bba31a13efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir classifcation_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc85080-aee6-4c33-9f89-125a2431ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 60\n",
    "loss_all = []\n",
    "\n",
    "for epoch in range(2):\n",
    "    np.random.shuffle(files)\n",
    "    for i, file in enumerate(tqdm(files)):\n",
    "\n",
    "\n",
    "        data_objects = convert_for_classification(file, restructure=False)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        dl = DataLoader(data_objects, batch_size=len(data_objects))\n",
    "\n",
    "        for batch in dl:\n",
    "            batch = batch.to(device)\n",
    "            y_hat = model(batch)\n",
    "            y_hat = y_hat.mean(0)\n",
    "            y_true = batch.y[0]\n",
    "\n",
    "            loss = criterion(y_hat, y_true) \n",
    "            loss.backward()\n",
    "            loss_all.append(loss.item())\n",
    "            optimizer.step()\n",
    "\n",
    "            if i != 0 and i % 20000 == 0:\n",
    "                loss_all = np.mean(loss_all)\n",
    "                print(f\"loss {loss_all}\")\n",
    "                torch.save(model.state_dict(), \"./classifcation_model/mmc_diffpool_model_classification_norestruct_intermediate\" + str(epoch) + \"_\" + str(i) + \".pth\")\n",
    "                os.system(f'echo \"Epoch: {epoch:03d}, Train Loss: {np.mean(loss_all):.4f}\" >> ./classifcation_model/mmc_diffpool_model_classification_norestruct_intermediate.txt')\n",
    "                loss_all = []\n",
    "                \n",
    "    torch.save(model.state_dict(), \"./classifcation_model/mmc_diffpool_model_classification_norestruct_\" + str(epoch) + \"_\" + str(i) + \".pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe2039-9c8f-4904-a770-b31e5299fa91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a115278-caba-4181-bf9f-7d63a5cd0f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "12a7011a-d20d-4f65-9feb-f9fd43e93d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 26900/26900 [00:42<00:00, 639.58it/s]\n"
     ]
    }
   ],
   "source": [
    "y_trues = []\n",
    "y_hats = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i, file in enumerate(tqdm(files)):\n",
    "        \n",
    "        if i < 100:\n",
    "\n",
    "\n",
    "            data_objects = convert_for_classification(file)\n",
    "\n",
    "            dl = DataLoader(data_objects, batch_size=len(data_objects))\n",
    "\n",
    "            for batch in dl:\n",
    "                batch = batch.to(device)\n",
    "                y_hat = model(batch)\n",
    "                y_hat = y_hat.mean(0)\n",
    "                y_true = batch.y[0]\n",
    "\n",
    "            y_trues.append(y_true.cpu().item())\n",
    "            y_hats.append(torch.argmax(y_hat).cpu().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d01fb1d1-5417-4979-937b-27ae2503c789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 10,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 11,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1, 15,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  7,  0,  0,  1],\n",
       "       [ 0,  1,  0,  0,  0, 18,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1,  1, 14,  0],\n",
       "       [ 0,  0,  0,  0,  3,  0,  4,  5]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_trues, y_hats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5560e356-f834-4973-b877-08578e19c75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b45be9f7-2391-4d3e-961f-922bf504c84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a02ce-c222-442c-a826-4551907f8c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b2215a-f45b-4bca-935f-c3b4820fc780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4155a97d-416d-49cd-a7b9-2895138924ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
