{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de09faac-c911-45aa-8c3f-1b59c1b19fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/ubuntu/graphseq-inference/\")\n",
    "from graphseq_inference.data_utils import *\n",
    "from graphseq_inference.models import *\n",
    "from graphseq_inference.train_utils import *\n",
    "\n",
    "#!python /home/ubuntu/graphseq-inference/graphseq_inference/generate_alpha.py > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d33774b-ead1-45ed-8cc4-d752e6309d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mid_trees(ts):\n",
    "\n",
    "    for i, tree in enumerate(ts.trees()):\n",
    "        if tree.interval.left >= (ts.sequence_length/2):\n",
    "            break\n",
    "\n",
    "    first_tree = i-249\n",
    "    last_tree = i + 250\n",
    "    \n",
    "    trees = []\n",
    "    for j, tree in enumerate(ts.aslist()):\n",
    "        if j >= first_tree and j <= last_tree:\n",
    "            trees.append(tree)\n",
    "            \n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc6b75-5bb4-4265-b090-efa103a0108d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3532c8-5b61-4edb-a2fb-16579326a403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec57d5-6751-4b0a-93af-0b5ea24e0169",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./classification_dataset/\"\n",
    "\n",
    "files = os.listdir(directory)\n",
    "files = [directory +  file for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4379677-b19b-42fa-adfe-1342b919ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc37e8d-a9cb-4f90-a9a8-189e8bef91e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581c953-bf41-4931-a7f0-0370e0fcec72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "624225a9-d4ca-4e08-8896-e8a7e8bcf6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_lookup = {\n",
    "    \"kingman_selection_none\" : 0,\n",
    "    \"kingman_selection_weak\" : 1,\n",
    "    \"kingman_selection_medium\" : 2,\n",
    "    \"kingman_selection_strong\" : 3,\n",
    "    \n",
    "    \"beta_selection_a1.99-1.75\" : 4,\n",
    "    \"beta_selection_a1.75-1.50\" : 5,\n",
    "    \"beta_selection_a1.50-1.25\" : 6,\n",
    "    \"beta_selection_a1.25-1.01\" : 7,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c535ed-e1ae-42fa-b9f6-705cecd0e4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba2b77-0833-46ff-88e1-b73ea1e9e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preorder_dist(tree):\n",
    "    result = []\n",
    "    for root in tree.roots:\n",
    "        stack = [(root, (-1, root) , (tree.get_time(tree.root), 0))]\n",
    "        while len(stack) > 0:\n",
    "            u, pc, time = stack.pop()\n",
    "            result.append((u, pc, time))\n",
    "            for v in tree.children(u):\n",
    "                stack.append((v, (u,v) , (tree.get_time(u),tree.get_time(v))))\n",
    "    return result\n",
    "\n",
    "def restructure_result(result):\n",
    "\n",
    "\n",
    "    is_modified = True\n",
    "    while True:\n",
    "\n",
    "        if not is_modified: break\n",
    "        is_modified = False\n",
    "\n",
    "        for i, (idx_node, (parent, node), (time_parent, time_node)) in enumerate(result):\n",
    "            branch_length = time_parent - time_node\n",
    "            \n",
    "            \n",
    "            \n",
    "            #if branch_length < (time_parent*threshold) and branch_length != 0 and (parent != node):\n",
    "            \n",
    "\n",
    "            threshold = 20\n",
    "            \n",
    "            if time_parent < 200:\n",
    "                threshold = 20\n",
    "            \n",
    "            if time_parent < 20:\n",
    "                threshold = 2\n",
    "                \n",
    "            if time_parent < 10:\n",
    "                threshold = 1\n",
    "                \n",
    "            if time_parent < 5:\n",
    "                threshold = 0.5\n",
    "                \n",
    "            \n",
    "            if branch_length < threshold and branch_length != 0 and (parent != node):\n",
    "    \n",
    "                \n",
    "                new_time = (time_parent+time_node)/2\n",
    "                result[i] = (-1, (parent, parent), (time_parent, time_parent))\n",
    "                for j, (_, (p, n), (tp, tn)) in enumerate(result):\n",
    "                    if node == n:\n",
    "                        result[j] = (-1, (p, parent), (tp, time_parent))#\n",
    "                    if node == p:\n",
    "                        result[j] = (-1, (parent, n), (time_parent, tn))\n",
    "\n",
    "                is_modified = True\n",
    "                break\n",
    "\n",
    "    new_result = []\n",
    "    for a, (b,c), (d, e) in result:\n",
    "        if b != c:\n",
    "            new_result.append((a, (b,c), (d,e)))\n",
    "    return new_result\n",
    "\n",
    "def multiple_mergerized_to_data_object(result):\n",
    "\n",
    "    G = nx.Graph()\n",
    "    for _, edge, times in result[:-1]:\n",
    "        a, b = edge\n",
    "        ta, tb = times\n",
    "        branch = ta - tb\n",
    "        G.add_weighted_edges_from([(a, b, branch)])\n",
    "        \n",
    "    data = from_networkx(G)\n",
    "    rename_data_attribute(data, \"weight\", \"edge_weight\") \n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def tree_to_data_objects(tree, num_embedding=60):\n",
    "    max_num_nodes = 2 * 10 - 1 \n",
    "\n",
    "    data = from_networkx(nx.Graph(tree.as_dict_of_dicts()))\n",
    "    rename_data_attribute(data, \"branch_length\", \"edge_weight\") \n",
    "    num_nodes = data.num_nodes\n",
    "    data.x = torch.eye(max_num_nodes,num_embedding)\n",
    "    data.x[num_nodes:] = torch.zeros(num_embedding)\n",
    "    data.num_nodes = max_num_nodes\n",
    "    return data\n",
    "\n",
    "\n",
    "def tree_to_restructured_data_objects(tree, num_embedding=60):\n",
    "    result = preorder_dist(tree)\n",
    "    result.reverse()\n",
    "    result = restructure_result(result)    \n",
    "    data = multiple_mergerized_to_data_object(result)\n",
    "    \n",
    "    max_num_nodes = 2 * 10 - 1 \n",
    "    num_nodes = data.num_nodes\n",
    "    data.x = torch.eye(max_num_nodes,num_embedding)\n",
    "    data.x[num_nodes:] = torch.zeros(num_embedding)\n",
    "    data.num_nodes = max_num_nodes\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157ebe1d-8beb-4ae0-b4cc-2f8526b6981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_y_label_from_y_dict(y_dict):\n",
    "    reproduction_model, parameter = y_dict[\"model\"]\n",
    "\n",
    "    if reproduction_model == \"beta\":\n",
    "        if parameter < 1.25:\n",
    "            return torch.Tensor([7]).long()\n",
    "        if parameter < 1.5:\n",
    "            return torch.Tensor([6]).long()\n",
    "        if parameter < 1.75:\n",
    "            return torch.Tensor([5]).long()\n",
    "        if parameter < 2:\n",
    "            return torch.Tensor([4]).long()\n",
    "\n",
    "    else:\n",
    "        label = y_dict[\"model\"][0] + \"_selection_\" + y_dict[\"selection_type\"]\n",
    "        y = torch.Tensor([label_lookup[label]]).long()\n",
    "        return y\n",
    "\n",
    "def convert_for_classification(file: tskit.trees.TreeSequence,\n",
    "                                num_embedding:int = 60, restructure=False,\n",
    "                           ):\n",
    "    \n",
    "    ts, y_dict = torch.load(file)\n",
    "    \n",
    "    y = get_y_label_from_y_dict(y_dict)\n",
    "    \n",
    "    #label = y_dict[\"model\"][0] + \"_selection_\" + y_dict[\"selection_type\"]\n",
    "    #y = torch.Tensor([label_lookup[label]]).long()\n",
    "    trees = get_mid_trees(ts)\n",
    "    \n",
    "        \n",
    "    if restructure:\n",
    "        data_objects = [tree_to_restructured_data_objects(tree) for tree in trees]\n",
    "    else:\n",
    "        data_objects = [tree_to_data_objects(tree) for tree in trees]\n",
    "        \n",
    "    \n",
    "    for data in data_objects:\n",
    "        data.y = y\n",
    "    \n",
    "    \n",
    "    #for i, tree in enumerate(trees):            \n",
    "    #    data = from_networkx(nx.Graph(tree.as_dict_of_dicts()))\n",
    "    #    rename_data_attribute(data, \"branch_length\", \"edge_weight\") \n",
    "    #    num_nodes = data.num_nodes\n",
    "    #    data.x = torch.eye(max_num_nodes,num_embedding)\n",
    "    #    data.x[num_nodes:] = torch.zeros(num_embedding)\n",
    "    #    data.y = y\n",
    "    #    data.num_nodes = max_num_nodes\n",
    "    #    data_objects.append(data)\n",
    "        \n",
    "    return data_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72c07c39-b3b6-4c6c-8cea-1fe3f4c0fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = files[0]\n",
    "ts, y_dict = torch.load(file)\n",
    "y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aea0947b-6329-4242-afb2-61339b02f46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ('beta', 1.37),\n",
       " 'sequence_length': 409600000,\n",
       " 'selection_coefficient': 0,\n",
       " 'selection_type': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = files[2]\n",
    "ts, y_dict = torch.load(file)\n",
    "y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "69076931-94cd-4209-be2a-ca8999113a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ('beta', 1.74), 'sequence_length': 25600000, 'selection_coefficient': 0, 'selection_type': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_y_label_from_y_dict(y_dict):\n",
    "    reproduction_model, parameter = y_dict[\"model\"]\n",
    "\n",
    "    if reproduction_model == \"beta\":\n",
    "        if parameter < 1.25:\n",
    "            return torch.Tensor([7]).long()\n",
    "        if parameter < 1.5:\n",
    "            return torch.Tensor([6]).long()\n",
    "        if parameter < 1.75:\n",
    "            return torch.Tensor([5]).long()\n",
    "        if parameter < 2:\n",
    "            return torch.Tensor([4]).long()\n",
    "\n",
    "    else:\n",
    "        label = y_dict[\"model\"][0] + \"_selection_\" + y_dict[\"selection_type\"]\n",
    "        y = torch.Tensor([label_lookup[label]]).long()\n",
    "        return y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa78576-6824-460f-8230-55d1d035688e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37827073-a3d4-4912-88f8-2556f46a5ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbc2e12-d47e-4549-b84e-0092f8478fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, DemographyNet, num_classes, time_window=60):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(time_window, time_window//2)\n",
    "        self.l2 = nn.Linear(time_window//2, num_classes)\n",
    "        self.DemographyNet = DemographyNet\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        x = self.DemographyNet(batch)\n",
    "        return self.l2(F.relu(self.l1(x)))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7368a3a-313b-4b9b-b684-04780b037ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "demography_net = DiffPoolNet(19, 60, 192, 60)\n",
    "model = ClassificationModel(demography_net, num_classes=8).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "initialize_weights(model)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7da97947-3bee-4dc1-8ffc-7c05165ebb50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9d1e2da2-82af-4ba4-94af-0dfa87255a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb000c5e-916f-40d6-ab4e-29be86b159c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e4318-61d9-4061-9e55-bba31a13efd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc85080-aee6-4c33-9f89-125a2431ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 60\n",
    "loss_all = []\n",
    "\n",
    "for epoch in range(2):\n",
    "    np.random.shuffle(files)\n",
    "    for i, file in enumerate(tqdm(files)):\n",
    "\n",
    "\n",
    "        data_objects = convert_for_classification(file, restructure=False)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        dl = DataLoader(data_objects, batch_size=len(data_objects))\n",
    "\n",
    "        for batch in dl:\n",
    "            batch = batch.to(device)\n",
    "            y_hat = model(batch)\n",
    "            y_hat = y_hat.mean(0)\n",
    "            y_true = batch.y[0]\n",
    "\n",
    "            loss = criterion(y_hat, y_true) \n",
    "            loss.backward()\n",
    "            loss_all.append(loss.item())\n",
    "            optimizer.step()\n",
    "\n",
    "            if i != 0 and i % 20000 == 0:\n",
    "                loss_all = np.mean(loss_all)\n",
    "                print(f\"loss {loss_all}\")\n",
    "                torch.save(model.state_dict(), \"./classifcation_model/mmc_diffpool_model_classification_norestruct_intermediate\" + str(epoch) + \"_\" + str(i) + \".pth\")\n",
    "                os.system(f'echo \"Epoch: {epoch:03d}, Train Loss: {np.mean(loss_all):.4f}\" >> ./classifcation_model/mmc_diffpool_model_classification_norestruct_intermediate.txt')\n",
    "                loss_all = []\n",
    "                \n",
    "    torch.save(model.state_dict(), \"./classifcation_model/mmc_diffpool_model_classification_norestruct_\" + str(epoch) + \"_\" + str(i) + \".pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe2039-9c8f-4904-a770-b31e5299fa91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a115278-caba-4181-bf9f-7d63a5cd0f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5560e356-f834-4973-b877-08578e19c75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a02ce-c222-442c-a826-4551907f8c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b2215a-f45b-4bca-935f-c3b4820fc780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4155a97d-416d-49cd-a7b9-2895138924ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
