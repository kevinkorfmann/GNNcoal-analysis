{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b8ddd3b-a141-45c8-b1fe-106613419f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/ubuntu/graphseq-inference/\")\n",
    "from graphseq_inference.data_utils import *\n",
    "from graphseq_inference.models import *\n",
    "from graphseq_inference.train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d67ce27b-dd00-44a1-a872-fcdfe0a09cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1cf4def-9df6-4f05-9764-8372f566663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc99bc0e-beef-4bf4-8f22-311986ba3465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rm -rf ./20k_dataset/.ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c520394-43d8-4475-bf1c-e0d9a6308ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSELoss(yhat,y):\n",
    "    return torch.sqrt(torch.mean((yhat-y)**2))\n",
    "\n",
    "criterion = RMSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba2c97-f6fa-46c3-9fe3-4d0ab8b6d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tree_sequence_to_data_object(tree_sequence: tskit.trees.TreeSequence,\n",
    "                                                     parameters: np.ndarray,\n",
    "                                                     num_trees:int = 500,\n",
    "                                                     num_embedding:int = 60, \n",
    "                           ):\n",
    "    \n",
    "    population_size = parameters[\"pop_size_0\":\"pop_size_59\"].tolist() \n",
    "    y = torch.Tensor(population_size)\n",
    "    \n",
    "    max_num_nodes = 2 * tree_sequence.num_samples - 1 \n",
    "    data_objects = []\n",
    "    \n",
    "    #ts = tree_sequence\n",
    "    #ts = msprime.mutate(ts, 1e-8)\n",
    "    #ne = calculate_beta_coal_ne_estimate(ts.num_mutations, ts.sample_size, ts.sequence_length, parameters.model, 1e-8)\n",
    "    \n",
    "    for i, tree in enumerate(tree_sequence.trees()):\n",
    "        if i < num_trees:\n",
    "            \n",
    "            data = from_networkx(nx.Graph(tree.as_dict_of_dicts()))\n",
    "            rename_data_attribute(data, \"branch_length\", \"edge_weight\") \n",
    "            num_nodes = data.num_nodes\n",
    "            data.x = torch.eye(max_num_nodes,num_embedding)\n",
    "            data.x[num_nodes:] = torch.zeros(num_embedding)\n",
    "            data.y = torch.Tensor(torch.log(y))\n",
    "            data.num_nodes = max_num_nodes\n",
    "            \n",
    "            \n",
    "            \n",
    "            #data.edge_weight = data.edge_weight / ne\n",
    "            \n",
    "            data_objects.append(data)\n",
    "            \n",
    "        else: \n",
    "            break\n",
    "\n",
    "        \n",
    "    return data_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfe62cbf-5e3f-4eec-9228-8d8f2fd948fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "upper_out_of_bound = lower_out_of_bound = True\n",
    "while upper_out_of_bound or lower_out_of_bound:\n",
    "    steps = 18\n",
    "    x = np.log(get_population_time(time_rate=0.1, num_time_windows=steps, tmax=10_000_000).tolist())\n",
    "    y = np.log(sample_population_size(10_000, 10_000_000, steps))\n",
    "    xnew = np.linspace(x[0], x[-1], num=10000, endpoint=True)\n",
    "    f_cubic = interp1d(x, y, kind='cubic')\n",
    "    ynew = f_cubic(xnew)\n",
    "    upper_out_of_bound = np.sum(np.exp(ynew) > 10_000_000) > 0\n",
    "    lower_out_of_bound = np.sum(np.exp(ynew) < 10_000) > 0\n",
    "    \n",
    "x_sample = xnew[np.linspace(10, 9999, 60).astype(int)]\n",
    "y_sample = ynew[np.linspace(10, 9999, 60).astype(int)]\n",
    "\n",
    "population_time = np.exp(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "072af616-5bb0-4148-9a6b-75b26a522c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = pd.read_csv(\"20k_seed_0x1337_demographies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d874a-7feb-4fc8-9ec4-5cd3afbec814",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./20k_dataset/\"\n",
    "files = os.listdir(directory)\n",
    "files = [directory +  file for file in files]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf89a2-43a6-40d1-b302-d7b63119f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DiffPoolNet(19, 60, 192, 60).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "initialize_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e843c612-58a7-405d-97ee-b50ba7551118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no validation loop because training dataset is ridiculously large\n",
    "# and validation occurs later by choosing specific scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c889858-f922-4217-9376-db69f1a2139c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                | 1675/2000000 [14:00<258:21:01,  2.15it/s]"
     ]
    }
   ],
   "source": [
    "length = 60\n",
    "loss_all = []\n",
    "\n",
    "for epoch in range(0, 2):\n",
    "    np.random.shuffle(files)\n",
    "    for i in tqdm(range(0, len(files))):\n",
    "\n",
    "        file = files[i]\n",
    "        ts, mask = torch.load(file)\n",
    "        \n",
    "        nth_scenario = int(file.split(\"_\")[2])\n",
    "        \n",
    "\n",
    "        parameter_set = parameters.iloc[nth_scenario]\n",
    "        data_objects = convert_tree_sequence_to_data_object(ts, parameter_set)\n",
    "\n",
    "        if len(data_objects) > 1:\n",
    "        \n",
    "            mask[population_time <= 10] = False\n",
    "            mask = torch.tile(torch.Tensor(mask), (len(data_objects), 1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            dl = DataLoader(data_objects, batch_size=len(data_objects))\n",
    "            for batch in dl:\n",
    "                batch = batch.to(device)\n",
    "                y_hat = model(batch)\n",
    "                y_true = data_objects[0].y.tile(len(data_objects)).reshape(len(data_objects), length).to(device)\n",
    "\n",
    "                mask = mask.to(device)\n",
    "                mask = mask.bool()\n",
    "                y_true[~mask] = 0\n",
    "                y_hat[~mask] = 0\n",
    "                loss = criterion(y_hat, y_true) \n",
    "                loss.backward()\n",
    "                loss_all.append(loss.item())\n",
    "                optimizer.step()\n",
    "\n",
    "            #if i != 0 and i % 100000 == 0:\n",
    "            if i != 0 and i % 10000 == 0:\n",
    "\n",
    "                loss_all = np.mean(loss_all)\n",
    "                print(f\"loss {loss_all}\")\n",
    "                if i != 0 and i % 100000 == 0: torch.save(model.state_dict(), \"./large_models_demo_nescaling/mmc_diffpool_model_demography_inference_intermediate\" + str(epoch) + \"_\" + str(i) + \".pth\")\n",
    "                os.system(f'echo \"Epoch: {epoch:03d}, Train Loss: {np.mean(loss_all):.4f}\" >> ./large_models_demo_nescaling/mmc_diffpool_model_demography_inference_intermediate.txt')\n",
    "                loss_all = []\n",
    "                \n",
    "    torch.save(model.state_dict(), \"./trained_models/demography_models//mmc_diffpool_model_demography_inference\" + str(epoch) + \"_\" + str(i) + \".pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
